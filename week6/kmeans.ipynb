{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "kmeans.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b14c9b76"
      },
      "source": [
        "# 2 K-Means Clustering\n",
        "In this notebook we will explore and cluster data with the K-Means algorithm.\n",
        "\n",
        "In K-Means, a dataset is partitioned in _k_ clusters while trying to minimise the sum of squared distances of each point to its cluster centre. On of the characteristics of this algorithm is that the number of clusters _k_ is predefined, i.e. the choice is left to the machine learning practitioner.\n",
        "\n",
        "You can find an overview of the algorithm on page 23 in the lecture.\n",
        "\n",
        "Before we start however, we need a package that we did not use before, _ipywidgets_. We will use it later for a dynamic visualisation of our clusters."
      ],
      "id": "b14c9b76"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33f81626",
        "outputId": "e1419517-53bc-4634-958c-e7f6303512ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install ipywidgets"
      ],
      "id": "33f81626",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.0.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.3.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (57.0.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c1d94ed"
      },
      "source": [
        "No we can import the usual packages."
      ],
      "id": "2c1d94ed"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6da3ea0"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "%config InlineBackend.figure_format = 'svg' # matplotlib magic\n",
        "np.random.seed(1337) # seeds help with reproducible results"
      ],
      "id": "c6da3ea0",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "244287e0"
      },
      "source": [
        "## 2.1 The dataset\n",
        "We are going to use familiar data, the Iris flower dataset.\n",
        "However, the dataset contains four features. We want to be able to look at our clustering results later. Four dimensional data is hard to visualise for human brains. Thankfully, we know a handy dimensionality reduction technique."
      ],
      "id": "244287e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46570a43"
      },
      "source": [
        "### Task 2.1.1 Transform the data\n",
        "- Load the Iris dataset with the provided function.\n",
        "- Use the PCA class from sklearn to project the dataset into a two-dimensional space."
      ],
      "id": "46570a43"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "248ffd7b"
      },
      "source": [
        "iris_data = load_iris()\n",
        "np.shape(iris_data['data'])\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(iris_data['data'])\n",
        "iris_pca = pca.transform(iris_data['data'])\n",
        "# your code here"
      ],
      "id": "248ffd7b",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce11724d"
      },
      "source": [
        "## 2.2 Initialization\n",
        "Before we start with the learning phase, we need to set up a few initial parameters."
      ],
      "id": "ce11724d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ff5afb1"
      },
      "source": [
        "### Task 2.2.1 The _k_-Question\n",
        "As mentioned, the choice of the right _k_ is an important decision for the success of the algorithm. The number of clusters you will stare at in the end, depends on _k_. Too many or too few clusters might give you suboptimal results.\n",
        "\n",
        "Fortunately, we know that the Iris dataset is labeled. Those labels already partition the data. Therefore, let's choose _k_ according to the number of labels."
      ],
      "id": "4ff5afb1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77ab12dc"
      },
      "source": [
        "k = 3# your code here"
      ],
      "id": "77ab12dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ef4a844"
      },
      "source": [
        "### Task 2.2.2 The first cluster centres\n",
        "You have to start somewhere! Theoretically, you could choose arbitrary points in the input space. Unfortunately, if we choose those randomly, it might take a while to converge.\n",
        "\n",
        "In order to speed things up a little, let's choose different random datapoints as the initial cluster centres and put them into a list/array.\n",
        "\n",
        "_Hint:_ np.random has a few good functions for that purpose."
      ],
      "id": "3ef4a844"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aa1298c",
        "outputId": "2fa54568-6f9d-43de-f1ba-50af863801bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnd = [ np.random.randint(0, len(iris_pca)) for i in range(3) ]\n",
        "# print(rnd)\n",
        "rnd_data_point = [ iris_pca[rnd] for i in range(rnd) ]\n",
        "print(rnd_data_point)"
      ],
      "id": "4aa1298c",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-2.6727558  -0.11377425]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50439bf1"
      },
      "source": [
        "## 2.3 The Algorithm\n",
        "Now the algorithm goes as follows:\n",
        "\n",
        "    - obtain the distance of each point to each cluster centre\n",
        "    - assign that point to the nearest cluster\n",
        "    - move position of centre to mean of points in cluster\n",
        "    \n",
        "Thus, we need to calculate a few things."
      ],
      "id": "50439bf1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51013379"
      },
      "source": [
        "### Task 2.3.1 Compute the distances\n",
        "Complete the function _distances()_ that takes a list/array of datapoints and a list/array of cluster centres and returns the distance of each datapoint to each cluster centre."
      ],
      "id": "51013379"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37a5553d"
      },
      "source": [
        "def distances(data, centroids):\n",
        "    # your code here"
      ],
      "id": "37a5553d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea6ee35c"
      },
      "source": [
        "### Task 2.3.2 Assign to clusters\n",
        "Now that we can compute the distances to the cluster centres, we need to assign the points to their respective clusters.\n",
        "\n",
        "Complete the function _compute\\_assignments()_ that takes a list/array of datapoints and a list/array of cluster centres and returns a list of assignments of each data point to the nearest cluster centre.\n",
        "\n",
        "_Hint:_ Make ample use of the _distances()_ function you just wrote."
      ],
      "id": "ea6ee35c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da0a1298"
      },
      "source": [
        "def compute_assignments(data, centroids):\n",
        "    # your code here"
      ],
      "id": "da0a1298",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3634ee8"
      },
      "source": [
        "### Task 2.3.3 New cluster centres\n",
        "Now that we have our clusters, we can compute new centres that better represent the cluster.\n",
        "\n",
        "Complete the function _compute\\_new\\_centres()_ that takes takes a list/array of datapoints and a list/array of assignments and returns the new cluster centres."
      ],
      "id": "b3634ee8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86afd505"
      },
      "source": [
        "def compute_new_centres(data, assignments):\n",
        "    # your code here"
      ],
      "id": "86afd505",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "683ad50e"
      },
      "source": [
        "The most important parts are done! Theoretically, we only need to run the algorithm repeatedly until the cluster centres do not change anymore."
      ],
      "id": "683ad50e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25db7af0"
      },
      "source": [
        "## 2.4 Cluster quality\n",
        "As we have seen in previous assignments, blindly running an algorithm without evaluating the quality of its results is not always the best idea.\n",
        "\n",
        "Hence, we will use the Davies Bouldin Index to evaluate the quality of our clusters (see also page 18 in the lecture).\n",
        "\n",
        "### Task 2.4.1 The Davies-Bouldin-Index\n",
        "\n",
        "Write a function _db\\_index()_ that takes a list/array of datapoints, a list/array of cluster centres and a list/array of assignments and returns the Davies-Bouldin Index.\n",
        "\n",
        "You will need to:\n",
        "    \n",
        "    - calculate the radii of the clusters, R\n",
        "    - calculate the inter class distance between the clusters\n",
        "    - calculate the badness of separation between the clusters, D\n",
        "    \n",
        "Lastly, you need to average over the relevant D-values of each cluster.\n",
        "\n",
        "All necessary formulas can be found in lecture 19, \"Basic Clustering."
      ],
      "id": "25db7af0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "749be475"
      },
      "source": [
        "def db_index(data, centroids, assignments):\n",
        "    # your code here\n"
      ],
      "id": "749be475",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc520992"
      },
      "source": [
        "## 2.5 Learning Phase"
      ],
      "id": "fc520992"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b02c602"
      },
      "source": [
        "### Task 2.5.1 Iterative Clustering\n",
        "Finally, we have all the ingredients in order to cluster our data. Remember, we already initialised the first cluster centres.\n",
        "\n",
        "Therefore, for 20 iterations, you will need to:\n",
        "\n",
        "    - compute the cluster assignments\n",
        "    - compute the new cluster centres according to the assignments\n",
        "    - compute the DB index for the current assignments and cluster centres\n",
        "    \n",
        "Do not forget to log relevant data for each iteration:\n",
        "\n",
        "    - the cluster centres\n",
        "    - the cluster assignments\n",
        "    - the DB-Index"
      ],
      "id": "2b02c602"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97cbd5c3"
      },
      "source": [
        "iterations = 20\n",
        "\n",
        "# your code here"
      ],
      "id": "97cbd5c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ebe3dab"
      },
      "source": [
        "## 2.6 Evaluation"
      ],
      "id": "7ebe3dab"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "649c71de"
      },
      "source": [
        "### Task 2.6.1 Plotting the DB-Index\n",
        "Plot the DB-Index over the iterations."
      ],
      "id": "649c71de"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "783eee93"
      },
      "source": [
        "%matplotlib inline\n",
        "# your code here"
      ],
      "id": "783eee93",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5936529"
      },
      "source": [
        "### Task 2.6.2 Plotting the Cluster Assignments\n",
        "In order to see how the clusters evolve over the iterations, plotting the state of the iterations over and over again is a bit cumbersome. Therefore we are going to use some matplotlib magic to make an interactive plot within this notebook.\n",
        "\n",
        "The _plot\\_clusters()_ function takes as an argument the current iteration and updates the plot with the relevant data from the iteration. If everything works out, you can then use the interaction slider to go back and forth between the iterations and see how the clusters develop."
      ],
      "id": "d5936529"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ed810b0f"
      },
      "source": [
        "%matplotlib widget\n",
        "_, ax = plt.subplots()\n",
        "\n",
        "    \n",
        "def plot_clusters(iteration):\n",
        "    iter_assignments = # get current cluster assignments\n",
        "    iter_centres = # get current cluster centres\n",
        "    ax.clear()\n",
        "    ax.set_xlabel('YOUR LABEL HERE')\n",
        "    ax.set_ylabel('YOUR LABEL HERE')\n",
        "    ax.set_title('YOUR TITLE HERE')\n",
        "    \n",
        "    # Plot each cluster\n",
        "    for i in range(k):\n",
        "        points = # get data points belonging to cluster i\n",
        "        ax.scatter(points[:, 0], points[:, 1], color=\"C{}\".format(i), s=20)\n",
        "        ax.scatter(iter_centres[i, 0], iter_centres[i, 1], color=\"C{}\".format(i), \n",
        "                   marker='s', s=50, edgecolor=\"black\", linewidth=2)\n",
        "    \n",
        "\n",
        "iteraction_slider = widgets.IntSlider(min=0, max=iterations-1, description='Iteration:')\n",
        "widgets.interact(plot_clusters, iteration=iteraction_slider);"
      ],
      "id": "ed810b0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86be0a85"
      },
      "source": [
        "### Task 2.6.3 Clustered Data vs Labeled Data\n",
        "In the beginning, we told our K-Means algorithm to separate the data into three clusters, because we have labels that also separate the data into three parts.\n",
        "\n",
        "Create two plots side-by-side (using subplots), where one side is showing the clustered data and the other side is showing the partitions of the labeled data. "
      ],
      "id": "86be0a85"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aa93c2c"
      },
      "source": [
        "%matplotlib inline\n",
        "# your code here"
      ],
      "id": "1aa93c2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b70e277"
      },
      "source": [
        "## 2.7 K-Means in the wild\n",
        "It is quite fun to write the K-Means algorithm from the ground up. But, usually, a practitioner would rely on libraries, which have already implemented the algorithm, if possible.\n",
        "K-Means is implemented in the sk-learn library, so we are going to use it cluster somewhat more complex data and visualise the cluster centres."
      ],
      "id": "4b70e277"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a94936e"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.cluster import KMeans"
      ],
      "id": "9a94936e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c2e9057"
      },
      "source": [
        "### Task 2.7.1 Digits data and the K-Question\n",
        "Load the digits data set and decide the obvious question of how many cluster centres we want to have."
      ],
      "id": "1c2e9057"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f18ff1c"
      },
      "source": [
        "# your code here"
      ],
      "id": "0f18ff1c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54338297"
      },
      "source": [
        "### Task 2.7.2 Run the K-Means algorithm\n",
        "Use the provided KMeans object on the digits data and extract the cluster centres"
      ],
      "id": "54338297"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a339e4e4"
      },
      "source": [
        "# your code here"
      ],
      "id": "a339e4e4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9088e4b0"
      },
      "source": [
        "### 2.7.3 Plot the Cluster Centres\n",
        "Plot all the extracted cluster centres"
      ],
      "id": "9088e4b0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb43b124"
      },
      "source": [
        "%matplotlib inline\n",
        "# your code here"
      ],
      "id": "eb43b124",
      "execution_count": null,
      "outputs": []
    }
  ]
}