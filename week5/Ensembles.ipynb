{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583d1489",
   "metadata": {},
   "source": [
    "# 1 Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b86ad2",
   "metadata": {},
   "source": [
    "This task will be some hands-on programming of two different ensemble learning techniques, i.e. bagging and boosting. More specifically, we will use the [Bagging Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) as well as [AdaBoost Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) provided by the scikit-learn library.\n",
    "\n",
    "As you are already familiar with loading datasets, splitting into training and test data, fitting a classifier etc., we will this time just give you hints about what steps to do. Also, we will give you some libraries to import, so that you have a good impression already about what you might need for this task. You can use additional imports of course, but please stick with the libraries we have used in this course so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad011a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Additional imports here, if needed\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df304a",
   "metadata": {},
   "source": [
    "## 1.1 Load and Split **Digits** Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcaef78",
   "metadata": {},
   "source": [
    "### Task 1.1.1 Load dataset \n",
    "\n",
    "Load the [Digits Toy Dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#digits-dataset) provided by Scikit-Learn and save it in the variable given below. Make sure that **all 10 digits** are included in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = # your code here\n",
    "\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0525e20",
   "metadata": {},
   "source": [
    "### Task 1.1.2 Save feature and target data\n",
    "\n",
    "Save the feature data from the dataset (i.e. the vectors representing the digits) and the respective target labels in two different variables *X* and *y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075926da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = # your code here\n",
    "y = # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322257b",
   "metadata": {},
   "source": [
    "### Task 1.1.3 Split train and test data\n",
    "\n",
    "Split all data into train and test set, denoting your training set *(X_train, y_train)* and your test set *(X_test, y_test)*. We want to have 70% of the samples for training and 30% of the samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3a37e",
   "metadata": {},
   "source": [
    "## Task 1.2 Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a684cb0",
   "metadata": {},
   "source": [
    "### Task 1.2.1 Train Classifier\n",
    "\n",
    "Create a **Bagging Classifier** object and train it on the given training data you got from task 1.1.3. You can play with different sets of parameters for the classifier (such as number of estimators etc.), but please keep the original base estimator (i.e. decision tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b33171",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = # your code here (bagging classifier object)\n",
    "\n",
    "bc_model = # your code here (trained classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6aed0d",
   "metadata": {},
   "source": [
    "### Task 1.2.2 Evaluate Classifier\n",
    "\n",
    "Now it's time to see how the classifier performs. Make the prediction of target labels *y_pred* based on the test samples and print the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = # your code here\n",
    "\n",
    "bc_accuracy = # your code here\n",
    "\n",
    "print(\"Accuracy of Bagging Classifier on Digits Dataset: %.4f\" % bc_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2cb57",
   "metadata": {},
   "source": [
    "Great, you're done! Now it's time to do the same few steps using the AdaBoost classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3ad56",
   "metadata": {},
   "source": [
    "## Task 1.3 AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6890d1ce",
   "metadata": {},
   "source": [
    "### Task 1.3.1 Train Classifier\n",
    "\n",
    "Create an **AdaBoost Classifier** object and train it on the given training data you got from task 1.1.3. You can play with different sets of parameters for the classifier (such as number of estimators, learning rate etc.), but please keep the original base estimator (i.e. decision tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07eab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = # your code here (AdaBoost classifier object)\n",
    "\n",
    "abc_model = # your code here (trained classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50442418",
   "metadata": {},
   "source": [
    "### Task 1.3.2 Evaluate Classifier\n",
    "\n",
    "Once again it's time to see how the classifier performs. Make the prediction of target labels *y_pred* based on the test samples and print the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f853f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = # your code here\n",
    "\n",
    "abc_accuracy = # your code here\n",
    "\n",
    "print(\"Accuracy of AdaBoost Classifier on Digits Dataset: %.4f\" % abc_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da78ccc",
   "metadata": {},
   "source": [
    "_________________________\n",
    "\n",
    "You're done! Are the accuracy results as you had expected? If not, feel free to adjust some parameters to maximize your outcome. Either way, you might have just written your very first ensemble classifiers in python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3d2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
